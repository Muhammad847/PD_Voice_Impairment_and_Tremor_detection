{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PD_Dummy_DataFrame = pd.read_csv('parkinsons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parkinson_csv = pd.read_csv('parkinsons.csv')\n",
    "Parkinson_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parkinson_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features from target\n",
    "# Remove the 'status' and 'name' columns\n",
    "X = Parkinson_csv.drop(columns=['status', 'name'])\n",
    "y = Parkinson_csv['status']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create PCA instance\n",
    "n_components = 10  # Choose the number of principal components\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the data using PCA\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.82929965, -0.43616456, -0.95203729, ...,  0.48047686,\n",
       "        -0.21053082,  0.86888575],\n",
       "       [-0.77097169, -0.53097409, -0.05772056, ...,  1.31118546,\n",
       "         0.27507712,  1.80360503],\n",
       "       [-0.90947638, -0.7231683 , -0.10987483, ...,  1.01768236,\n",
       "        -0.10362861,  1.40266141],\n",
       "       ...,\n",
       "       [ 0.49557839,  0.47010361, -0.96839309, ..., -0.81807931,\n",
       "         0.78033848, -0.83241014],\n",
       "       [ 1.07876114,  2.19004398, -0.95417967, ..., -0.22906571,\n",
       "        -0.63700298, -0.92610456],\n",
       "       [ 1.45481664,  0.69224632, -0.88348115, ..., -0.43085284,\n",
       "         0.45480231, -0.64505466]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.58900504 0.1129943  0.07009226 0.06659028 0.04426891 0.03314129\n",
      " 0.02510204 0.01647288 0.01317446 0.01018756]\n"
     ]
    }
   ],
   "source": [
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratio:\", explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ... Your code to create PCA and scatter plot ...\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title(\"PCA Scatter Plot for Parkinson's Data\")\n",
    "\n",
    "# Adding a cherry on top\n",
    "plt.scatter([0], [0], marker='o', color='red', s=200, label='PD affected')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create classifier object\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier using the training data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py\", line 527, in __call__\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 705, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Best Hyperparameters: {'n_neighbors': 3}\n",
      "KNN - Best Score: nan\n",
      "SVM - Best Hyperparameters: {'C': 1, 'kernel': 'linear'}\n",
      "SVM - Best Score: 0.8655241935483872\n",
      "Logistic Regression - Best Hyperparameters: {'C': 10}\n",
      "Logistic Regression - Best Score: 0.8528225806451614\n",
      "Random Forest - Best Hyperparameters: {'max_depth': None, 'n_estimators': 100}\n",
      "Random Forest - Best Score: 0.9100806451612904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Load your dataset (replace with your dataset loading code)\n",
    "data = Parkinson_csv\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grids for each algorithm\n",
    "param_grid_knn = {'n_neighbors': [3, 5, 7, 9]}\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "param_grid_lr = {'C': [0.1, 1, 10]}\n",
    "param_grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "\n",
    "# Create instances of the classifiers\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create GridSearchCV instances for each classifier\n",
    "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5)\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=5)\n",
    "grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=5)\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV instances\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and best scores for each algorithm\n",
    "print(\"KNN - Best Hyperparameters:\", grid_search_knn.best_params_)\n",
    "print(\"KNN - Best Score:\", grid_search_knn.best_score_)\n",
    "print(\"SVM - Best Hyperparameters:\", grid_search_svm.best_params_)\n",
    "print(\"SVM - Best Score:\", grid_search_svm.best_score_)\n",
    "print(\"Logistic Regression - Best Hyperparameters:\", grid_search_lr.best_params_)\n",
    "print(\"Logistic Regression - Best Score:\", grid_search_lr.best_score_)\n",
    "print(\"Random Forest - Best Hyperparameters:\", grid_search_rf.best_params_)\n",
    "print(\"Random Forest - Best Score:\", grid_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>112.239</td>\n",
       "      <td>126.609</td>\n",
       "      <td>104.095</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.00715</td>\n",
       "      <td>0.05643</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04451</td>\n",
       "      <td>0.09211</td>\n",
       "      <td>0.02629</td>\n",
       "      <td>17.366</td>\n",
       "      <td>0.640945</td>\n",
       "      <td>0.701404</td>\n",
       "      <td>-5.634576</td>\n",
       "      <td>0.306014</td>\n",
       "      <td>2.419253</td>\n",
       "      <td>0.209191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>144.188</td>\n",
       "      <td>349.259</td>\n",
       "      <td>82.764</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00211</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02908</td>\n",
       "      <td>0.01859</td>\n",
       "      <td>22.333</td>\n",
       "      <td>0.567380</td>\n",
       "      <td>0.644692</td>\n",
       "      <td>-5.440040</td>\n",
       "      <td>0.239764</td>\n",
       "      <td>2.264501</td>\n",
       "      <td>0.218164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>117.870</td>\n",
       "      <td>127.349</td>\n",
       "      <td>95.654</td>\n",
       "      <td>0.00647</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.01067</td>\n",
       "      <td>0.03087</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02402</td>\n",
       "      <td>0.04977</td>\n",
       "      <td>0.02631</td>\n",
       "      <td>22.431</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>0.652025</td>\n",
       "      <td>-3.583722</td>\n",
       "      <td>0.207914</td>\n",
       "      <td>2.439597</td>\n",
       "      <td>0.206256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>159.116</td>\n",
       "      <td>168.913</td>\n",
       "      <td>144.811</td>\n",
       "      <td>0.00342</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00178</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>0.03381</td>\n",
       "      <td>0.307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02809</td>\n",
       "      <td>0.05417</td>\n",
       "      <td>0.00852</td>\n",
       "      <td>22.663</td>\n",
       "      <td>0.366329</td>\n",
       "      <td>0.693429</td>\n",
       "      <td>-6.417440</td>\n",
       "      <td>0.194627</td>\n",
       "      <td>2.473239</td>\n",
       "      <td>0.151709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>143.533</td>\n",
       "      <td>162.215</td>\n",
       "      <td>65.809</td>\n",
       "      <td>0.01101</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.00647</td>\n",
       "      <td>0.00467</td>\n",
       "      <td>0.01941</td>\n",
       "      <td>0.05384</td>\n",
       "      <td>0.478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03392</td>\n",
       "      <td>0.09455</td>\n",
       "      <td>0.04882</td>\n",
       "      <td>20.338</td>\n",
       "      <td>0.513237</td>\n",
       "      <td>0.731444</td>\n",
       "      <td>-5.869750</td>\n",
       "      <td>0.151814</td>\n",
       "      <td>2.118496</td>\n",
       "      <td>0.185580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>121.345</td>\n",
       "      <td>139.644</td>\n",
       "      <td>98.250</td>\n",
       "      <td>0.00684</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00388</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.01164</td>\n",
       "      <td>0.02534</td>\n",
       "      <td>0.241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02056</td>\n",
       "      <td>0.04019</td>\n",
       "      <td>0.04179</td>\n",
       "      <td>21.520</td>\n",
       "      <td>0.566867</td>\n",
       "      <td>0.670475</td>\n",
       "      <td>-4.865194</td>\n",
       "      <td>0.246404</td>\n",
       "      <td>2.013530</td>\n",
       "      <td>0.168581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>109.860</td>\n",
       "      <td>126.358</td>\n",
       "      <td>104.437</td>\n",
       "      <td>0.00874</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>0.01193</td>\n",
       "      <td>0.03209</td>\n",
       "      <td>0.307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.05368</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>20.767</td>\n",
       "      <td>0.558586</td>\n",
       "      <td>0.811843</td>\n",
       "      <td>-4.333543</td>\n",
       "      <td>0.221727</td>\n",
       "      <td>2.014606</td>\n",
       "      <td>0.344834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>142.167</td>\n",
       "      <td>217.455</td>\n",
       "      <td>83.159</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00157</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.00471</td>\n",
       "      <td>0.01503</td>\n",
       "      <td>0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01359</td>\n",
       "      <td>0.02316</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0.565924</td>\n",
       "      <td>0.658245</td>\n",
       "      <td>-5.340115</td>\n",
       "      <td>0.210185</td>\n",
       "      <td>2.205546</td>\n",
       "      <td>0.234589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>204.664</td>\n",
       "      <td>221.300</td>\n",
       "      <td>189.621</td>\n",
       "      <td>0.00841</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>0.01506</td>\n",
       "      <td>0.02378</td>\n",
       "      <td>0.210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>0.03831</td>\n",
       "      <td>0.01316</td>\n",
       "      <td>21.305</td>\n",
       "      <td>0.498877</td>\n",
       "      <td>0.722085</td>\n",
       "      <td>-4.876336</td>\n",
       "      <td>0.212054</td>\n",
       "      <td>2.376749</td>\n",
       "      <td>0.268144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>208.519</td>\n",
       "      <td>220.315</td>\n",
       "      <td>199.020</td>\n",
       "      <td>0.00609</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00368</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.01105</td>\n",
       "      <td>0.01761</td>\n",
       "      <td>0.155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01307</td>\n",
       "      <td>0.02855</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>22.407</td>\n",
       "      <td>0.338097</td>\n",
       "      <td>0.712466</td>\n",
       "      <td>-6.471427</td>\n",
       "      <td>0.184378</td>\n",
       "      <td>2.502336</td>\n",
       "      <td>0.136390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>116.848</td>\n",
       "      <td>217.552</td>\n",
       "      <td>99.503</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00260</td>\n",
       "      <td>0.00346</td>\n",
       "      <td>0.00780</td>\n",
       "      <td>0.01795</td>\n",
       "      <td>0.163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.02429</td>\n",
       "      <td>0.01179</td>\n",
       "      <td>22.085</td>\n",
       "      <td>0.663842</td>\n",
       "      <td>0.656516</td>\n",
       "      <td>-5.198864</td>\n",
       "      <td>0.206768</td>\n",
       "      <td>2.120412</td>\n",
       "      <td>0.252404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>153.046</td>\n",
       "      <td>175.829</td>\n",
       "      <td>68.623</td>\n",
       "      <td>0.00742</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00364</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.05517</td>\n",
       "      <td>0.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05767</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0.03160</td>\n",
       "      <td>17.280</td>\n",
       "      <td>0.665318</td>\n",
       "      <td>0.719467</td>\n",
       "      <td>-3.949079</td>\n",
       "      <td>0.357870</td>\n",
       "      <td>3.109010</td>\n",
       "      <td>0.377429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>100.960</td>\n",
       "      <td>110.019</td>\n",
       "      <td>95.628</td>\n",
       "      <td>0.00606</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00351</td>\n",
       "      <td>0.00348</td>\n",
       "      <td>0.01053</td>\n",
       "      <td>0.02427</td>\n",
       "      <td>0.216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01751</td>\n",
       "      <td>0.04114</td>\n",
       "      <td>0.01237</td>\n",
       "      <td>20.536</td>\n",
       "      <td>0.554610</td>\n",
       "      <td>0.787896</td>\n",
       "      <td>-5.022288</td>\n",
       "      <td>0.146948</td>\n",
       "      <td>2.428306</td>\n",
       "      <td>0.264666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95.056</td>\n",
       "      <td>120.103</td>\n",
       "      <td>91.226</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.00803</td>\n",
       "      <td>0.02838</td>\n",
       "      <td>0.255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02444</td>\n",
       "      <td>0.04324</td>\n",
       "      <td>0.01022</td>\n",
       "      <td>21.862</td>\n",
       "      <td>0.547037</td>\n",
       "      <td>0.798463</td>\n",
       "      <td>-5.011879</td>\n",
       "      <td>0.325996</td>\n",
       "      <td>2.432792</td>\n",
       "      <td>0.271362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>102.273</td>\n",
       "      <td>142.830</td>\n",
       "      <td>85.902</td>\n",
       "      <td>0.00907</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.00493</td>\n",
       "      <td>0.00461</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.02814</td>\n",
       "      <td>0.272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02073</td>\n",
       "      <td>0.04736</td>\n",
       "      <td>0.03882</td>\n",
       "      <td>18.447</td>\n",
       "      <td>0.671378</td>\n",
       "      <td>0.674562</td>\n",
       "      <td>-2.929379</td>\n",
       "      <td>0.396746</td>\n",
       "      <td>2.560422</td>\n",
       "      <td>0.367233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>170.756</td>\n",
       "      <td>450.247</td>\n",
       "      <td>79.032</td>\n",
       "      <td>0.00555</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.00731</td>\n",
       "      <td>0.01725</td>\n",
       "      <td>0.175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01652</td>\n",
       "      <td>0.02270</td>\n",
       "      <td>0.01802</td>\n",
       "      <td>25.690</td>\n",
       "      <td>0.486738</td>\n",
       "      <td>0.676023</td>\n",
       "      <td>-4.597834</td>\n",
       "      <td>0.372114</td>\n",
       "      <td>2.975889</td>\n",
       "      <td>0.282780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>148.090</td>\n",
       "      <td>162.824</td>\n",
       "      <td>67.343</td>\n",
       "      <td>0.00762</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00467</td>\n",
       "      <td>0.00354</td>\n",
       "      <td>0.01400</td>\n",
       "      <td>0.05428</td>\n",
       "      <td>0.497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03635</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>21.718</td>\n",
       "      <td>0.487407</td>\n",
       "      <td>0.727313</td>\n",
       "      <td>-6.261141</td>\n",
       "      <td>0.120956</td>\n",
       "      <td>2.137075</td>\n",
       "      <td>0.141958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>210.141</td>\n",
       "      <td>232.706</td>\n",
       "      <td>185.258</td>\n",
       "      <td>0.00534</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00321</td>\n",
       "      <td>0.00280</td>\n",
       "      <td>0.00964</td>\n",
       "      <td>0.01680</td>\n",
       "      <td>0.149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01301</td>\n",
       "      <td>0.02583</td>\n",
       "      <td>0.00620</td>\n",
       "      <td>23.671</td>\n",
       "      <td>0.441097</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>-5.963040</td>\n",
       "      <td>0.250283</td>\n",
       "      <td>2.489191</td>\n",
       "      <td>0.177807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>174.688</td>\n",
       "      <td>240.005</td>\n",
       "      <td>74.287</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>0.256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.10715</td>\n",
       "      <td>17.883</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.655683</td>\n",
       "      <td>-6.787197</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>2.679772</td>\n",
       "      <td>0.131728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>217.116</td>\n",
       "      <td>233.481</td>\n",
       "      <td>93.978</td>\n",
       "      <td>0.00404</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00127</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.00381</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01075</td>\n",
       "      <td>0.02038</td>\n",
       "      <td>0.00681</td>\n",
       "      <td>24.581</td>\n",
       "      <td>0.462516</td>\n",
       "      <td>0.582710</td>\n",
       "      <td>-5.517173</td>\n",
       "      <td>0.389295</td>\n",
       "      <td>2.925862</td>\n",
       "      <td>0.220657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>182.018</td>\n",
       "      <td>197.173</td>\n",
       "      <td>79.187</td>\n",
       "      <td>0.00842</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00506</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>0.01517</td>\n",
       "      <td>0.02503</td>\n",
       "      <td>0.231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0.04115</td>\n",
       "      <td>0.01813</td>\n",
       "      <td>18.784</td>\n",
       "      <td>0.589956</td>\n",
       "      <td>0.732903</td>\n",
       "      <td>-5.445140</td>\n",
       "      <td>0.142466</td>\n",
       "      <td>2.174306</td>\n",
       "      <td>0.215558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>202.544</td>\n",
       "      <td>241.350</td>\n",
       "      <td>164.168</td>\n",
       "      <td>0.00254</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00301</td>\n",
       "      <td>0.02662</td>\n",
       "      <td>0.228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02006</td>\n",
       "      <td>0.04426</td>\n",
       "      <td>0.01049</td>\n",
       "      <td>20.680</td>\n",
       "      <td>0.497480</td>\n",
       "      <td>0.630409</td>\n",
       "      <td>-6.132663</td>\n",
       "      <td>0.220617</td>\n",
       "      <td>2.576563</td>\n",
       "      <td>0.159777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>140.341</td>\n",
       "      <td>159.774</td>\n",
       "      <td>67.021</td>\n",
       "      <td>0.00817</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00430</td>\n",
       "      <td>0.00440</td>\n",
       "      <td>0.01289</td>\n",
       "      <td>0.03198</td>\n",
       "      <td>0.313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02428</td>\n",
       "      <td>0.05490</td>\n",
       "      <td>0.02183</td>\n",
       "      <td>19.560</td>\n",
       "      <td>0.460139</td>\n",
       "      <td>0.720908</td>\n",
       "      <td>-5.409423</td>\n",
       "      <td>0.226850</td>\n",
       "      <td>2.359973</td>\n",
       "      <td>0.226156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>242.852</td>\n",
       "      <td>255.034</td>\n",
       "      <td>227.911</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.00117</td>\n",
       "      <td>0.00139</td>\n",
       "      <td>0.00350</td>\n",
       "      <td>0.01494</td>\n",
       "      <td>0.134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.00476</td>\n",
       "      <td>25.032</td>\n",
       "      <td>0.431285</td>\n",
       "      <td>0.638928</td>\n",
       "      <td>-6.995820</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>2.365800</td>\n",
       "      <td>0.102706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>126.144</td>\n",
       "      <td>154.284</td>\n",
       "      <td>97.543</td>\n",
       "      <td>0.00975</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.00593</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>0.02852</td>\n",
       "      <td>0.266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02157</td>\n",
       "      <td>0.04499</td>\n",
       "      <td>0.03828</td>\n",
       "      <td>21.534</td>\n",
       "      <td>0.635015</td>\n",
       "      <td>0.627337</td>\n",
       "      <td>-5.070096</td>\n",
       "      <td>0.280091</td>\n",
       "      <td>2.892300</td>\n",
       "      <td>0.249703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>151.872</td>\n",
       "      <td>492.892</td>\n",
       "      <td>69.085</td>\n",
       "      <td>0.00856</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00404</td>\n",
       "      <td>0.00385</td>\n",
       "      <td>0.01211</td>\n",
       "      <td>0.01843</td>\n",
       "      <td>0.235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01271</td>\n",
       "      <td>0.02389</td>\n",
       "      <td>0.06051</td>\n",
       "      <td>23.693</td>\n",
       "      <td>0.407701</td>\n",
       "      <td>0.662668</td>\n",
       "      <td>-4.673241</td>\n",
       "      <td>0.261549</td>\n",
       "      <td>2.702355</td>\n",
       "      <td>0.274407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>136.969</td>\n",
       "      <td>166.607</td>\n",
       "      <td>66.004</td>\n",
       "      <td>0.00923</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.00507</td>\n",
       "      <td>0.00463</td>\n",
       "      <td>0.01520</td>\n",
       "      <td>0.03111</td>\n",
       "      <td>0.308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02603</td>\n",
       "      <td>0.04914</td>\n",
       "      <td>0.02659</td>\n",
       "      <td>19.979</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.729067</td>\n",
       "      <td>-5.324574</td>\n",
       "      <td>0.205660</td>\n",
       "      <td>2.291558</td>\n",
       "      <td>0.226247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>152.125</td>\n",
       "      <td>161.469</td>\n",
       "      <td>76.596</td>\n",
       "      <td>0.00382</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00226</td>\n",
       "      <td>0.00574</td>\n",
       "      <td>0.05925</td>\n",
       "      <td>0.637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>0.10024</td>\n",
       "      <td>0.01211</td>\n",
       "      <td>20.969</td>\n",
       "      <td>0.447456</td>\n",
       "      <td>0.697790</td>\n",
       "      <td>-6.152551</td>\n",
       "      <td>0.173520</td>\n",
       "      <td>2.080121</td>\n",
       "      <td>0.160809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>197.076</td>\n",
       "      <td>206.896</td>\n",
       "      <td>192.055</td>\n",
       "      <td>0.00289</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00166</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>0.01098</td>\n",
       "      <td>0.097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00802</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>26.775</td>\n",
       "      <td>0.422229</td>\n",
       "      <td>0.741367</td>\n",
       "      <td>-7.348300</td>\n",
       "      <td>0.177551</td>\n",
       "      <td>1.743867</td>\n",
       "      <td>0.085569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>128.451</td>\n",
       "      <td>150.449</td>\n",
       "      <td>75.632</td>\n",
       "      <td>0.01551</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.00905</td>\n",
       "      <td>0.00909</td>\n",
       "      <td>0.02716</td>\n",
       "      <td>0.06170</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05174</td>\n",
       "      <td>0.09669</td>\n",
       "      <td>0.11843</td>\n",
       "      <td>15.060</td>\n",
       "      <td>0.639808</td>\n",
       "      <td>0.643327</td>\n",
       "      <td>-4.202730</td>\n",
       "      <td>0.310163</td>\n",
       "      <td>2.638279</td>\n",
       "      <td>0.356881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>178.285</td>\n",
       "      <td>442.824</td>\n",
       "      <td>82.063</td>\n",
       "      <td>0.00462</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00157</td>\n",
       "      <td>0.00194</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>0.01279</td>\n",
       "      <td>0.129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01151</td>\n",
       "      <td>0.01851</td>\n",
       "      <td>0.00856</td>\n",
       "      <td>25.020</td>\n",
       "      <td>0.470422</td>\n",
       "      <td>0.655239</td>\n",
       "      <td>-4.913137</td>\n",
       "      <td>0.393056</td>\n",
       "      <td>2.816781</td>\n",
       "      <td>0.251972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>110.707</td>\n",
       "      <td>122.611</td>\n",
       "      <td>105.007</td>\n",
       "      <td>0.00516</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.00289</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.02215</td>\n",
       "      <td>0.206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01715</td>\n",
       "      <td>0.03851</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>25.197</td>\n",
       "      <td>0.463514</td>\n",
       "      <td>0.807217</td>\n",
       "      <td>-5.477592</td>\n",
       "      <td>0.315074</td>\n",
       "      <td>1.862092</td>\n",
       "      <td>0.228624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>163.656</td>\n",
       "      <td>200.841</td>\n",
       "      <td>76.779</td>\n",
       "      <td>0.00742</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.01140</td>\n",
       "      <td>0.01659</td>\n",
       "      <td>0.164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01497</td>\n",
       "      <td>0.02214</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>23.831</td>\n",
       "      <td>0.397937</td>\n",
       "      <td>0.732479</td>\n",
       "      <td>-5.557447</td>\n",
       "      <td>0.220890</td>\n",
       "      <td>2.692176</td>\n",
       "      <td>0.215961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>110.739</td>\n",
       "      <td>113.597</td>\n",
       "      <td>100.139</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.00170</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00510</td>\n",
       "      <td>0.01484</td>\n",
       "      <td>0.133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01285</td>\n",
       "      <td>0.02261</td>\n",
       "      <td>0.00430</td>\n",
       "      <td>26.550</td>\n",
       "      <td>0.369090</td>\n",
       "      <td>0.776158</td>\n",
       "      <td>-6.085567</td>\n",
       "      <td>0.192375</td>\n",
       "      <td>1.889002</td>\n",
       "      <td>0.174152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>166.888</td>\n",
       "      <td>198.966</td>\n",
       "      <td>79.512</td>\n",
       "      <td>0.00638</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00368</td>\n",
       "      <td>0.00351</td>\n",
       "      <td>0.01104</td>\n",
       "      <td>0.02857</td>\n",
       "      <td>0.257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02301</td>\n",
       "      <td>0.04641</td>\n",
       "      <td>0.01796</td>\n",
       "      <td>18.330</td>\n",
       "      <td>0.585169</td>\n",
       "      <td>0.736964</td>\n",
       "      <td>-5.825257</td>\n",
       "      <td>0.115697</td>\n",
       "      <td>1.996146</td>\n",
       "      <td>0.196535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>240.301</td>\n",
       "      <td>245.135</td>\n",
       "      <td>219.783</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>0.00283</td>\n",
       "      <td>0.00949</td>\n",
       "      <td>0.02018</td>\n",
       "      <td>0.212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01344</td>\n",
       "      <td>0.03529</td>\n",
       "      <td>0.00965</td>\n",
       "      <td>21.020</td>\n",
       "      <td>0.371837</td>\n",
       "      <td>0.646167</td>\n",
       "      <td>-7.169701</td>\n",
       "      <td>0.073298</td>\n",
       "      <td>2.266432</td>\n",
       "      <td>0.100881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156.405</td>\n",
       "      <td>189.398</td>\n",
       "      <td>142.822</td>\n",
       "      <td>0.00768</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00372</td>\n",
       "      <td>0.00399</td>\n",
       "      <td>0.01116</td>\n",
       "      <td>0.03995</td>\n",
       "      <td>0.348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04310</td>\n",
       "      <td>0.05164</td>\n",
       "      <td>0.03365</td>\n",
       "      <td>17.153</td>\n",
       "      <td>0.649554</td>\n",
       "      <td>0.686080</td>\n",
       "      <td>-4.554466</td>\n",
       "      <td>0.340176</td>\n",
       "      <td>2.856676</td>\n",
       "      <td>0.322111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>197.569</td>\n",
       "      <td>217.627</td>\n",
       "      <td>90.794</td>\n",
       "      <td>0.00803</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.01470</td>\n",
       "      <td>0.02177</td>\n",
       "      <td>0.189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01439</td>\n",
       "      <td>0.03836</td>\n",
       "      <td>0.01337</td>\n",
       "      <td>19.269</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.725216</td>\n",
       "      <td>-5.736781</td>\n",
       "      <td>0.164529</td>\n",
       "      <td>2.882450</td>\n",
       "      <td>0.202879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>112.014</td>\n",
       "      <td>588.518</td>\n",
       "      <td>107.024</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.00329</td>\n",
       "      <td>0.00805</td>\n",
       "      <td>0.02448</td>\n",
       "      <td>0.226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01956</td>\n",
       "      <td>0.04120</td>\n",
       "      <td>0.00623</td>\n",
       "      <td>24.178</td>\n",
       "      <td>0.509127</td>\n",
       "      <td>0.789532</td>\n",
       "      <td>-5.389129</td>\n",
       "      <td>0.306636</td>\n",
       "      <td>1.928708</td>\n",
       "      <td>0.225461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "138      112.239       126.609       104.095         0.00472   \n",
       "16       144.188       349.259        82.764         0.00544   \n",
       "155      117.870       127.349        95.654         0.00647   \n",
       "96       159.116       168.913       144.811         0.00342   \n",
       "68       143.533       162.215        65.809         0.01101   \n",
       "153      121.345       139.644        98.250         0.00684   \n",
       "55       109.860       126.358       104.437         0.00874   \n",
       "15       142.167       217.455        83.159         0.00369   \n",
       "112      204.664       221.300       189.621         0.00841   \n",
       "111      208.519       220.315       199.020         0.00609   \n",
       "184      116.848       217.552        99.503         0.00531   \n",
       "18       153.046       175.829        68.623         0.00742   \n",
       "82       100.960       110.019        95.628         0.00606   \n",
       "9         95.056       120.103        91.226         0.00532   \n",
       "164      102.273       142.830        85.902         0.00907   \n",
       "117      170.756       450.247        79.032         0.00555   \n",
       "69       148.090       162.824        67.343         0.00762   \n",
       "113      210.141       232.706       185.258         0.00534   \n",
       "192      174.688       240.005        74.287         0.01360   \n",
       "119      217.116       233.481        93.978         0.00404   \n",
       "123      182.018       197.173        79.187         0.00842   \n",
       "144      202.544       241.350       164.168         0.00254   \n",
       "66       140.341       159.774        67.021         0.00817   \n",
       "45       242.852       255.034       227.911         0.00225   \n",
       "158      126.144       154.284        97.543         0.00975   \n",
       "115      151.872       492.892        69.085         0.00856   \n",
       "67       136.969       166.607        66.004         0.00923   \n",
       "93       152.125       161.469        76.596         0.00382   \n",
       "30       197.076       206.896       192.055         0.00289   \n",
       "101      128.451       150.449        75.632         0.01551   \n",
       "118      178.285       442.824        82.063         0.00462   \n",
       "75       110.707       122.611       105.007         0.00516   \n",
       "24       163.656       200.841        76.779         0.00742   \n",
       "172      110.739       113.597       100.139         0.00356   \n",
       "127      166.888       198.966        79.512         0.00638   \n",
       "169      240.301       245.135       219.783         0.00517   \n",
       "19       156.405       189.398       142.822         0.00768   \n",
       "168      197.569       217.627        90.794         0.00803   \n",
       "73       112.014       588.518       107.024         0.00533   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
       "138          0.000040   0.00238   0.00290     0.00715       0.05643   \n",
       "16           0.000040   0.00211   0.00292     0.00632       0.02047   \n",
       "155          0.000050   0.00356   0.00300     0.01067       0.03087   \n",
       "96           0.000020   0.00178   0.00184     0.00535       0.03381   \n",
       "68           0.000080   0.00647   0.00467     0.01941       0.05384   \n",
       "153          0.000060   0.00388   0.00332     0.01164       0.02534   \n",
       "55           0.000080   0.00398   0.00539     0.01193       0.03209   \n",
       "15           0.000030   0.00157   0.00203     0.00471       0.01503   \n",
       "112          0.000040   0.00502   0.00485     0.01506       0.02378   \n",
       "111          0.000030   0.00368   0.00339     0.01105       0.01761   \n",
       "184          0.000050   0.00260   0.00346     0.00780       0.01795   \n",
       "18           0.000050   0.00364   0.00432     0.01092       0.05517   \n",
       "82           0.000060   0.00351   0.00348     0.01053       0.02427   \n",
       "9            0.000060   0.00268   0.00332     0.00803       0.02838   \n",
       "164          0.000090   0.00493   0.00461     0.01480       0.02814   \n",
       "117          0.000030   0.00244   0.00261     0.00731       0.01725   \n",
       "69           0.000050   0.00467   0.00354     0.01400       0.05428   \n",
       "113          0.000030   0.00321   0.00280     0.00964       0.01680   \n",
       "192          0.000080   0.00624   0.00564     0.01873       0.02308   \n",
       "119          0.000020   0.00127   0.00128     0.00381       0.01299   \n",
       "123          0.000050   0.00506   0.00449     0.01517       0.02503   \n",
       "144          0.000010   0.00100   0.00133     0.00301       0.02662   \n",
       "66           0.000060   0.00430   0.00440     0.01289       0.03198   \n",
       "45           0.000009   0.00117   0.00139     0.00350       0.01494   \n",
       "158          0.000080   0.00593   0.00454     0.01778       0.02852   \n",
       "115          0.000060   0.00404   0.00385     0.01211       0.01843   \n",
       "67           0.000070   0.00507   0.00463     0.01520       0.03111   \n",
       "93           0.000030   0.00191   0.00226     0.00574       0.05925   \n",
       "30           0.000010   0.00166   0.00168     0.00498       0.01098   \n",
       "101          0.000120   0.00905   0.00909     0.02716       0.06170   \n",
       "118          0.000030   0.00157   0.00194     0.00472       0.01279   \n",
       "75           0.000050   0.00277   0.00289     0.00831       0.02215   \n",
       "24           0.000050   0.00380   0.00390     0.01140       0.01659   \n",
       "172          0.000030   0.00170   0.00200     0.00510       0.01484   \n",
       "127          0.000040   0.00368   0.00351     0.01104       0.02857   \n",
       "169          0.000020   0.00316   0.00283     0.00949       0.02018   \n",
       "19           0.000050   0.00372   0.00399     0.01116       0.03995   \n",
       "168          0.000040   0.00490   0.00448     0.01470       0.02177   \n",
       "73           0.000050   0.00268   0.00329     0.00805       0.02448   \n",
       "\n",
       "     MDVP:Shimmer(dB)  ...  MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE  \\\n",
       "138             0.517  ...   0.04451      0.09211  0.02629  17.366  0.640945   \n",
       "16              0.192  ...   0.02074      0.02908  0.01859  22.333  0.567380   \n",
       "155             0.276  ...   0.02402      0.04977  0.02631  22.431  0.628300   \n",
       "96              0.307  ...   0.02809      0.05417  0.00852  22.663  0.366329   \n",
       "68              0.478  ...   0.03392      0.09455  0.04882  20.338  0.513237   \n",
       "153             0.241  ...   0.02056      0.04019  0.04179  21.520  0.566867   \n",
       "55              0.307  ...   0.02454      0.05368  0.01180  20.767  0.558586   \n",
       "15              0.126  ...   0.01359      0.02316  0.00839  25.175  0.565924   \n",
       "112             0.210  ...   0.01767      0.03831  0.01316  21.305  0.498877   \n",
       "111             0.155  ...   0.01307      0.02855  0.00830  22.407  0.338097   \n",
       "184             0.163  ...   0.01756      0.02429  0.01179  22.085  0.663842   \n",
       "18              0.542  ...   0.05767      0.07413  0.03160  17.280  0.665318   \n",
       "82              0.216  ...   0.01751      0.04114  0.01237  20.536  0.554610   \n",
       "9               0.255  ...   0.02444      0.04324  0.01022  21.862  0.547037   \n",
       "164             0.272  ...   0.02073      0.04736  0.03882  18.447  0.671378   \n",
       "117             0.175  ...   0.01652      0.02270  0.01802  25.690  0.486738   \n",
       "69              0.497  ...   0.03635      0.10070  0.02431  21.718  0.487407   \n",
       "113             0.149  ...   0.01301      0.02583  0.00620  23.671  0.441097   \n",
       "192             0.256  ...   0.01667      0.03804  0.10715  17.883  0.407567   \n",
       "119             0.124  ...   0.01075      0.02038  0.00681  24.581  0.462516   \n",
       "123             0.231  ...   0.01931      0.04115  0.01813  18.784  0.589956   \n",
       "144             0.228  ...   0.02006      0.04426  0.01049  20.680  0.497480   \n",
       "66              0.313  ...   0.02428      0.05490  0.02183  19.560  0.460139   \n",
       "45              0.134  ...   0.01014      0.02542  0.00476  25.032  0.431285   \n",
       "158             0.266  ...   0.02157      0.04499  0.03828  21.534  0.635015   \n",
       "115             0.235  ...   0.01271      0.02389  0.06051  23.693  0.407701   \n",
       "67              0.308  ...   0.02603      0.04914  0.02659  19.979  0.498133   \n",
       "93              0.637  ...   0.04398      0.10024  0.01211  20.969  0.447456   \n",
       "30              0.097  ...   0.00802      0.01689  0.00339  26.775  0.422229   \n",
       "101             0.584  ...   0.05174      0.09669  0.11843  15.060  0.639808   \n",
       "118             0.129  ...   0.01151      0.01851  0.00856  25.020  0.470422   \n",
       "75              0.206  ...   0.01715      0.03851  0.00472  25.197  0.463514   \n",
       "24              0.164  ...   0.01497      0.02214  0.01778  23.831  0.397937   \n",
       "172             0.133  ...   0.01285      0.02261  0.00430  26.550  0.369090   \n",
       "127             0.257  ...   0.02301      0.04641  0.01796  18.330  0.585169   \n",
       "169             0.212  ...   0.01344      0.03529  0.00965  21.020  0.371837   \n",
       "19              0.348  ...   0.04310      0.05164  0.03365  17.153  0.649554   \n",
       "168             0.189  ...   0.01439      0.03836  0.01337  19.269  0.372222   \n",
       "73              0.226  ...   0.01956      0.04120  0.00623  24.178  0.509127   \n",
       "\n",
       "          DFA   spread1   spread2        D2       PPE  \n",
       "138  0.701404 -5.634576  0.306014  2.419253  0.209191  \n",
       "16   0.644692 -5.440040  0.239764  2.264501  0.218164  \n",
       "155  0.652025 -3.583722  0.207914  2.439597  0.206256  \n",
       "96   0.693429 -6.417440  0.194627  2.473239  0.151709  \n",
       "68   0.731444 -5.869750  0.151814  2.118496  0.185580  \n",
       "153  0.670475 -4.865194  0.246404  2.013530  0.168581  \n",
       "55   0.811843 -4.333543  0.221727  2.014606  0.344834  \n",
       "15   0.658245 -5.340115  0.210185  2.205546  0.234589  \n",
       "112  0.722085 -4.876336  0.212054  2.376749  0.268144  \n",
       "111  0.712466 -6.471427  0.184378  2.502336  0.136390  \n",
       "184  0.656516 -5.198864  0.206768  2.120412  0.252404  \n",
       "18   0.719467 -3.949079  0.357870  3.109010  0.377429  \n",
       "82   0.787896 -5.022288  0.146948  2.428306  0.264666  \n",
       "9    0.798463 -5.011879  0.325996  2.432792  0.271362  \n",
       "164  0.674562 -2.929379  0.396746  2.560422  0.367233  \n",
       "117  0.676023 -4.597834  0.372114  2.975889  0.282780  \n",
       "69   0.727313 -6.261141  0.120956  2.137075  0.141958  \n",
       "113  0.722254 -5.963040  0.250283  2.489191  0.177807  \n",
       "192  0.655683 -6.787197  0.158453  2.679772  0.131728  \n",
       "119  0.582710 -5.517173  0.389295  2.925862  0.220657  \n",
       "123  0.732903 -5.445140  0.142466  2.174306  0.215558  \n",
       "144  0.630409 -6.132663  0.220617  2.576563  0.159777  \n",
       "66   0.720908 -5.409423  0.226850  2.359973  0.226156  \n",
       "45   0.638928 -6.995820  0.102083  2.365800  0.102706  \n",
       "158  0.627337 -5.070096  0.280091  2.892300  0.249703  \n",
       "115  0.662668 -4.673241  0.261549  2.702355  0.274407  \n",
       "67   0.729067 -5.324574  0.205660  2.291558  0.226247  \n",
       "93   0.697790 -6.152551  0.173520  2.080121  0.160809  \n",
       "30   0.741367 -7.348300  0.177551  1.743867  0.085569  \n",
       "101  0.643327 -4.202730  0.310163  2.638279  0.356881  \n",
       "118  0.655239 -4.913137  0.393056  2.816781  0.251972  \n",
       "75   0.807217 -5.477592  0.315074  1.862092  0.228624  \n",
       "24   0.732479 -5.557447  0.220890  2.692176  0.215961  \n",
       "172  0.776158 -6.085567  0.192375  1.889002  0.174152  \n",
       "127  0.736964 -5.825257  0.115697  1.996146  0.196535  \n",
       "169  0.646167 -7.169701  0.073298  2.266432  0.100881  \n",
       "19   0.686080 -4.554466  0.340176  2.856676  0.322111  \n",
       "168  0.725216 -5.736781  0.164529  2.882450  0.202879  \n",
       "73   0.789532 -5.389129  0.306636  1.928708  0.225461  \n",
       "\n",
       "[39 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <td>112.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <td>126.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <td>104.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <td>0.004720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <td>0.002380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <td>0.007150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <td>0.056430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:APQ3</th>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:APQ5</th>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <td>0.044510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <td>0.092110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHR</th>\n",
       "      <td>0.026290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HNR</th>\n",
       "      <td>17.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPDE</th>\n",
       "      <td>0.640945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFA</th>\n",
       "      <td>0.701404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread1</th>\n",
       "      <td>-5.634576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread2</th>\n",
       "      <td>0.306014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>2.419253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPE</th>\n",
       "      <td>0.209191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         138\n",
       "MDVP:Fo(Hz)       112.239000\n",
       "MDVP:Fhi(Hz)      126.609000\n",
       "MDVP:Flo(Hz)      104.095000\n",
       "MDVP:Jitter(%)      0.004720\n",
       "MDVP:Jitter(Abs)    0.000040\n",
       "MDVP:RAP            0.002380\n",
       "MDVP:PPQ            0.002900\n",
       "Jitter:DDP          0.007150\n",
       "MDVP:Shimmer        0.056430\n",
       "MDVP:Shimmer(dB)    0.517000\n",
       "Shimmer:APQ3        0.030700\n",
       "Shimmer:APQ5        0.035300\n",
       "MDVP:APQ            0.044510\n",
       "Shimmer:DDA         0.092110\n",
       "NHR                 0.026290\n",
       "HNR                17.366000\n",
       "RPDE                0.640945\n",
       "DFA                 0.701404\n",
       "spread1            -5.634576\n",
       "spread2             0.306014\n",
       "D2                  2.419253\n",
       "PPE                 0.209191"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[[0]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138    1\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Forest_Model = RandomForestClassifier(max_depth=None, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487179487179487"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random_Forest_Model.fit(X_train, y_train)\n",
    "Random_Forest_Model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <td>112.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <td>126.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <td>104.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <td>0.004720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <td>0.002380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <td>0.007150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <td>0.056430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:APQ3</th>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:APQ5</th>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <td>0.044510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <td>0.092110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHR</th>\n",
       "      <td>0.026290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HNR</th>\n",
       "      <td>17.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPDE</th>\n",
       "      <td>0.640945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFA</th>\n",
       "      <td>0.701404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread1</th>\n",
       "      <td>-5.634576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread2</th>\n",
       "      <td>0.306014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>2.419253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPE</th>\n",
       "      <td>0.209191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         138\n",
       "MDVP:Fo(Hz)       112.239000\n",
       "MDVP:Fhi(Hz)      126.609000\n",
       "MDVP:Flo(Hz)      104.095000\n",
       "MDVP:Jitter(%)      0.004720\n",
       "MDVP:Jitter(Abs)    0.000040\n",
       "MDVP:RAP            0.002380\n",
       "MDVP:PPQ            0.002900\n",
       "Jitter:DDP          0.007150\n",
       "MDVP:Shimmer        0.056430\n",
       "MDVP:Shimmer(dB)    0.517000\n",
       "Shimmer:APQ3        0.030700\n",
       "Shimmer:APQ5        0.035300\n",
       "MDVP:APQ            0.044510\n",
       "Shimmer:DDA         0.092110\n",
       "NHR                 0.026290\n",
       "HNR                17.366000\n",
       "RPDE                0.640945\n",
       "DFA                 0.701404\n",
       "spread1            -5.634576\n",
       "spread2             0.306014\n",
       "D2                  2.419253\n",
       "PPE                 0.209191"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[[0]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Input features as a list\n",
    "input_features = [\n",
    "    98.804000, 102.305000, 87.804000, 0.004320, 0.000040,\n",
    "    0.002470, 0.002580, 0.007420, 0.022230, 0.202000,\n",
    "    0.012770, 0.013430, 0.015520, 0.038310, 0.008820,\n",
    "    22.244000, 0.576644, 0.772416, 6.025367, 0.078202,\n",
    "    2.053601, 0.177275\n",
    "]\n",
    "\n",
    "# Convert the input features to a 2D array\n",
    "input_features_array = [input_features]\n",
    "\n",
    "# Perform the prediction\n",
    "First_Prediction = Random_Forest_Model.predict(input_features_array)\n",
    "print(First_Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
      "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
      "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
      "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA',\n",
      "       'spread1', 'spread2', 'D2', 'PPE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Assuming X is your DataFrame of features\n",
    "column_names = Parkinson_csv.columns\n",
    "\n",
    "# Print the column names\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Component Names: ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10']\n"
     ]
    }
   ],
   "source": [
    "transformed_component_names = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "\n",
    "# Print the names of the transformed components\n",
    "print(\"Transformed Component Names:\", transformed_component_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0966143  -1.55060712 -1.26506987 -0.84000197 -0.7268687   1.10199147\n",
      "  -0.53858412 -0.16256607  0.35127025 -0.25690475]]\n",
      "0    1\n",
      "Name: status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "first_5_values = X_pca[:1]\n",
    "print(first_5_values)\n",
    "Output_value = y[:1]\n",
    "print(Output_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0  2.096614 -1.550607 -1.265070 -0.840002 -0.726869  1.101991 -0.538584   \n",
      "1  4.709331 -1.334593 -1.057654 -2.139739 -1.177907  0.754064  0.102320   \n",
      "2  3.852615 -1.426221 -1.824965 -1.163920 -1.265558  0.568478 -0.047684   \n",
      "3  4.134771 -1.581914 -1.388036 -1.463193 -1.405647  0.617057  0.016264   \n",
      "4  5.689690 -1.150314 -2.421017 -1.344791 -0.849936  0.939659 -0.107455   \n",
      "\n",
      "        PC8       PC9      PC10  \n",
      "0 -0.162566  0.351270 -0.256905  \n",
      "1 -0.232575  0.798009  0.130206  \n",
      "2 -0.103205  0.638250 -0.076864  \n",
      "3 -0.169903  0.906802  0.096672  \n",
      "4 -1.126961  1.180605  0.333008  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming you've loaded and preprocessed your data into 'X_scaled'\n",
    "# Create PCA instance\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the transformed values and component names\n",
    "transformed_df = pd.DataFrame(X_pca, columns=transformed_component_names)\n",
    "\n",
    "\n",
    "# Print the first few rows of the resulting DataFrame\n",
    "print(transformed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_component_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = transformed_df[transformed_component_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Best Hyperparameters: {'n_neighbors': 3}\n",
      "KNN - Best Score: 0.890725806451613\n",
      "SVM - Best Hyperparameters: {'C': 10, 'kernel': 'rbf'}\n",
      "SVM - Best Score: 0.8846774193548388\n",
      "Logistic Regression - Best Hyperparameters: {'C': 1}\n",
      "Logistic Regression - Best Score: 0.8465725806451614\n",
      "Random Forest - Best Hyperparameters: {'max_depth': 10, 'n_estimators': 200}\n",
      "Random Forest - Best Score: 0.8975806451612904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
    "    X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grids for each algorithm\n",
    "param_grid_knn = {'n_neighbors': [3, 5, 7, 9]}\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "param_grid_lr = {'C': [0.1, 1, 10]}\n",
    "param_grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "\n",
    "# Create instances of the classifiers\n",
    "knn1 = KNeighborsClassifier()\n",
    "svm1 = SVC()\n",
    "lr1 = LogisticRegression()\n",
    "rf1 = RandomForestClassifier()\n",
    "\n",
    "# Create GridSearchCV instances for each classifier\n",
    "grid_search_knn1 = GridSearchCV(knn1, param_grid_knn, cv=5)\n",
    "grid_search_svm1 = GridSearchCV(svm1, param_grid_svm, cv=5)\n",
    "grid_search_lr1 = GridSearchCV(lr1, param_grid_lr, cv=5)\n",
    "grid_search_rf1 = GridSearchCV(rf1, param_grid_rf, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV instances\n",
    "grid_search_knn1.fit(X1_train, y1_train)\n",
    "grid_search_svm1.fit(X1_train, y1_train)\n",
    "grid_search_lr1.fit(X1_train, y1_train)\n",
    "grid_search_rf1.fit(X1_train, y1_train)\n",
    "\n",
    "# Print the best hyperparameters and best scores for each algorithm\n",
    "print(\"KNN - Best Hyperparameters:\", grid_search_knn1.best_params_)\n",
    "print(\"KNN - Best Score:\", grid_search_knn1.best_score_)\n",
    "print(\"SVM - Best Hyperparameters:\", grid_search_svm1.best_params_)\n",
    "print(\"SVM - Best Score:\", grid_search_svm1.best_score_)\n",
    "print(\"Logistic Regression - Best Hyperparameters:\", grid_search_lr1.best_params_)\n",
    "print(\"Logistic Regression - Best Score:\", grid_search_lr1.best_score_)\n",
    "print(\"Random Forest - Best Hyperparameters:\", grid_search_rf1.best_params_)\n",
    "print(\"Random Forest - Best Score:\", grid_search_rf1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Second_Random_Forest_Model = RandomForestClassifier(\n",
    "    max_depth=None, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Second_Random_Forest_Model.fit(X1_train, y1_train)\n",
    "Second_Random_Forest_Model.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output 1\n",
      "The output of the model:[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use the trained k-NN classifier model to classify new, previously unseen objects\n",
    "# first example: a small fruit with mass 20g, width 4.3 cm, height 5.5 cm\n",
    "PD_affected = Second_Random_Forest_Model.predict([[2.1,  -1.7, -1.3, -0.85, -0.73,   1.1,\n",
    "                                                   -0.5, -0.2,  0.35, -0.26]])\n",
    "print(f\"Expected Output {y_test.iloc[0]}\")\n",
    "print(f\"The output of the model:{PD_affected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
